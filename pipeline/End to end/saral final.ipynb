{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/project_final/orbitals.pkl', 'rb') as f:\n",
    "    orbitals = pickle.load(f)\n",
    "\n",
    "with open('/project_final/maneuvers.pkl', 'rb') as f:\n",
    "    maneuvers = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "man = maneuvers['srl']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = orbitals['SARAL.csv'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.index = pd.to_datetime(df.index)\n",
    "\n",
    "# keep only year-month-day\n",
    "df.index = df.index.normalize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import random\n",
    "from itertools import product\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Input, LSTM, Dropout, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed=42):\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "    os.environ['TF_DETERMINISTIC_OPS'] = '1'\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sequences(data, window_size):\n",
    "    sequences, targets = [], []\n",
    "    for i in range(len(data) - window_size):\n",
    "        sequences.append(data[i:i+window_size])\n",
    "        targets.append(data[i+window_size][0])\n",
    "    return np.array(sequences), np.array(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_lstm_model(window_size, n_features, learning_rate, hidden_units, dropout_rate, fc_size):\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=(window_size, n_features)))\n",
    "    model.add(LSTM(hidden_units))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(fc_size, activation='tanh'))\n",
    "    model.add(Dense(1))\n",
    "    optimizer = Adam(learning_rate=learning_rate)\n",
    "    model.compile(optimizer=optimizer, loss='mae')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_residuals_with_maneuvers(residual_all, residual_index, man_dates):\n",
    "    man_dates_sorted = pd.to_datetime(man_dates).sort_values()\n",
    "    lstm_ae_df = pd.DataFrame({'date': residual_index, 'residual': residual_all})\n",
    "\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    plt.plot(lstm_ae_df[\"date\"], lstm_ae_df[\"residual\"], label=\"LSTM-AE Absolute Residual\", color='blue')\n",
    "\n",
    "    for d in man_dates_sorted:\n",
    "        plt.axvline(d, color='gray', linestyle='--', alpha=0.3)\n",
    "\n",
    "    plt.xlabel(\"Date\")\n",
    "    plt.ylabel(\"Abs Residual\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_timestamp_series_to_epoch(series):\n",
    "    return (\n",
    "        (series - pd.Timestamp(year=1970, month=1, day=1)) // pd.Timedelta(seconds=1)\n",
    "    ).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_simple_matching_precision_recall_for_one_threshold(\n",
    "    matching_max_days,\n",
    "    threshold,\n",
    "    series_ground_truth_manoeuvre_timestamps,\n",
    "    series_predictions,\n",
    "):\n",
    "    matching_max_distance_seconds = pd.Timedelta(days=matching_max_days).total_seconds()\n",
    "    dict_predictions_to_ground_truth = {}\n",
    "    dict_ground_truth_to_predictions = {}\n",
    "\n",
    "    manoeuvre_timestamps_seconds = convert_timestamp_series_to_epoch(series_ground_truth_manoeuvre_timestamps)\n",
    "    pred_time_stamps_seconds = convert_timestamp_series_to_epoch(series_predictions.index)\n",
    "    predictions = series_predictions.to_numpy()\n",
    "\n",
    "    for i in range(predictions.shape[0]):\n",
    "        if predictions[i] >= threshold:\n",
    "            left_index = np.searchsorted(\n",
    "                manoeuvre_timestamps_seconds, pred_time_stamps_seconds[i]\n",
    "            )\n",
    "\n",
    "            if left_index != 0:\n",
    "                left_index -= 1\n",
    "\n",
    "            index_of_closest = left_index\n",
    "\n",
    "            if (left_index < len(series_ground_truth_manoeuvre_timestamps) - 1) and (\n",
    "                abs(manoeuvre_timestamps_seconds[left_index] - pred_time_stamps_seconds[i])\n",
    "                > abs(manoeuvre_timestamps_seconds[left_index + 1] - pred_time_stamps_seconds[i])\n",
    "            ):\n",
    "                index_of_closest = left_index + 1\n",
    "\n",
    "            diff = abs(manoeuvre_timestamps_seconds[index_of_closest] - pred_time_stamps_seconds[i])\n",
    "\n",
    "            if diff < matching_max_distance_seconds:\n",
    "                dict_predictions_to_ground_truth[i] = (index_of_closest, diff)\n",
    "                if index_of_closest in dict_ground_truth_to_predictions:\n",
    "                    dict_ground_truth_to_predictions[index_of_closest].append(i)\n",
    "                else:\n",
    "                    dict_ground_truth_to_predictions[index_of_closest] = [i]\n",
    "\n",
    "    positive_prediction_indices = np.argwhere(predictions >= threshold)[:, 0]\n",
    "    list_false_positives = [\n",
    "        pred_ind for pred_ind in positive_prediction_indices if pred_ind not in dict_predictions_to_ground_truth\n",
    "    ]\n",
    "    list_false_negatives = [\n",
    "        true_ind for true_ind in np.arange(0, len(series_ground_truth_manoeuvre_timestamps))\n",
    "        if true_ind not in dict_ground_truth_to_predictions\n",
    "    ]\n",
    "\n",
    "    precision = len(dict_ground_truth_to_predictions) / (len(dict_ground_truth_to_predictions) + len(list_false_positives)) if (len(dict_ground_truth_to_predictions) + len(list_false_positives)) > 0 else 0.0\n",
    "    recall = len(dict_ground_truth_to_predictions) / (len(dict_ground_truth_to_predictions) + len(list_false_negatives)) if (len(dict_ground_truth_to_predictions) + len(list_false_negatives)) > 0 else 0.0\n",
    "\n",
    "    return (precision, recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_beta_score(precision, recall, beta=2):\n",
    "    beta_sq = beta ** 2\n",
    "    denom = (beta_sq * precision) + recall\n",
    "    if denom == 0:\n",
    "        return 0\n",
    "    return (1 + beta_sq) * precision * recall / denom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "man_dates = man['median_day_time'].sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "FIXED_WINDOW = 3 \n",
    "TRAIN_FRAC, VAL_FRAC, TEST_FRAC = 0.6, 0.2, 0.2 \n",
    "\n",
    "def time_split_index(idx, train_frac=0.7, val_frac=0.15):\n",
    "    n = len(idx)\n",
    "    i_train = int(n * train_frac)\n",
    "    i_val = int(n * (train_frac + val_frac))\n",
    "    return idx[:i_train], idx[i_train:i_val], idx[i_val:]\n",
    "\n",
    "train_idx, val_idx, test_idx = time_split_index(df.index, TRAIN_FRAC, VAL_FRAC)\n",
    "\n",
    "df_train = df.loc[train_idx]\n",
    "df_val   = df.loc[val_idx]\n",
    "df_test  = df.loc[test_idx]\n",
    "\n",
    "man_dates_train = man_dates[(man_dates >= train_idx.min()) & (man_dates <= train_idx.max())]\n",
    "man_dates_val   = man_dates[(man_dates >= val_idx.min()) & (man_dates <= val_idx.max())]\n",
    "man_dates_test  = man_dates[(man_dates >= test_idx.min()) & (man_dates <= test_idx.max())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching params: {'window_size': 3, 'learning_rate': 0.01, 'hidden_units': 16, 'dropout_rate': 0.0, 'fc_size': 8}\n",
      "Searching params: {'window_size': 3, 'learning_rate': 0.01, 'hidden_units': 16, 'dropout_rate': 0.0, 'fc_size': 16}\n",
      "Searching params: {'window_size': 3, 'learning_rate': 0.01, 'hidden_units': 16, 'dropout_rate': 0.0, 'fc_size': 32}\n",
      "Searching params: {'window_size': 3, 'learning_rate': 0.01, 'hidden_units': 16, 'dropout_rate': 0.0, 'fc_size': 64}\n",
      "Searching params: {'window_size': 3, 'learning_rate': 0.01, 'hidden_units': 16, 'dropout_rate': 0.3, 'fc_size': 8}\n",
      "Searching params: {'window_size': 3, 'learning_rate': 0.01, 'hidden_units': 16, 'dropout_rate': 0.3, 'fc_size': 16}\n",
      "Searching params: {'window_size': 3, 'learning_rate': 0.01, 'hidden_units': 16, 'dropout_rate': 0.3, 'fc_size': 32}\n",
      "Searching params: {'window_size': 3, 'learning_rate': 0.01, 'hidden_units': 16, 'dropout_rate': 0.3, 'fc_size': 64}\n",
      "Searching params: {'window_size': 3, 'learning_rate': 0.01, 'hidden_units': 16, 'dropout_rate': 0.5, 'fc_size': 8}\n",
      "Searching params: {'window_size': 3, 'learning_rate': 0.01, 'hidden_units': 16, 'dropout_rate': 0.5, 'fc_size': 16}\n",
      "Searching params: {'window_size': 3, 'learning_rate': 0.01, 'hidden_units': 16, 'dropout_rate': 0.5, 'fc_size': 32}\n",
      "Searching params: {'window_size': 3, 'learning_rate': 0.01, 'hidden_units': 16, 'dropout_rate': 0.5, 'fc_size': 64}\n",
      "Searching params: {'window_size': 3, 'learning_rate': 0.01, 'hidden_units': 32, 'dropout_rate': 0.0, 'fc_size': 8}\n",
      "Searching params: {'window_size': 3, 'learning_rate': 0.01, 'hidden_units': 32, 'dropout_rate': 0.0, 'fc_size': 16}\n",
      "Searching params: {'window_size': 3, 'learning_rate': 0.01, 'hidden_units': 32, 'dropout_rate': 0.0, 'fc_size': 32}\n",
      "Searching params: {'window_size': 3, 'learning_rate': 0.01, 'hidden_units': 32, 'dropout_rate': 0.0, 'fc_size': 64}\n",
      "Searching params: {'window_size': 3, 'learning_rate': 0.01, 'hidden_units': 32, 'dropout_rate': 0.3, 'fc_size': 8}\n",
      "Searching params: {'window_size': 3, 'learning_rate': 0.01, 'hidden_units': 32, 'dropout_rate': 0.3, 'fc_size': 16}\n",
      "Searching params: {'window_size': 3, 'learning_rate': 0.01, 'hidden_units': 32, 'dropout_rate': 0.3, 'fc_size': 32}\n",
      "Searching params: {'window_size': 3, 'learning_rate': 0.01, 'hidden_units': 32, 'dropout_rate': 0.3, 'fc_size': 64}\n",
      "Searching params: {'window_size': 3, 'learning_rate': 0.01, 'hidden_units': 32, 'dropout_rate': 0.5, 'fc_size': 8}\n",
      "Searching params: {'window_size': 3, 'learning_rate': 0.01, 'hidden_units': 32, 'dropout_rate': 0.5, 'fc_size': 16}\n",
      "Searching params: {'window_size': 3, 'learning_rate': 0.01, 'hidden_units': 32, 'dropout_rate': 0.5, 'fc_size': 32}\n",
      "Searching params: {'window_size': 3, 'learning_rate': 0.01, 'hidden_units': 32, 'dropout_rate': 0.5, 'fc_size': 64}\n",
      "Searching params: {'window_size': 3, 'learning_rate': 0.01, 'hidden_units': 64, 'dropout_rate': 0.0, 'fc_size': 8}\n",
      "Searching params: {'window_size': 3, 'learning_rate': 0.01, 'hidden_units': 64, 'dropout_rate': 0.0, 'fc_size': 16}\n",
      "Searching params: {'window_size': 3, 'learning_rate': 0.01, 'hidden_units': 64, 'dropout_rate': 0.0, 'fc_size': 32}\n",
      "Searching params: {'window_size': 3, 'learning_rate': 0.01, 'hidden_units': 64, 'dropout_rate': 0.0, 'fc_size': 64}\n",
      "Searching params: {'window_size': 3, 'learning_rate': 0.01, 'hidden_units': 64, 'dropout_rate': 0.3, 'fc_size': 8}\n",
      "Searching params: {'window_size': 3, 'learning_rate': 0.01, 'hidden_units': 64, 'dropout_rate': 0.3, 'fc_size': 16}\n",
      "Searching params: {'window_size': 3, 'learning_rate': 0.01, 'hidden_units': 64, 'dropout_rate': 0.3, 'fc_size': 32}\n",
      "Searching params: {'window_size': 3, 'learning_rate': 0.01, 'hidden_units': 64, 'dropout_rate': 0.3, 'fc_size': 64}\n",
      "Searching params: {'window_size': 3, 'learning_rate': 0.01, 'hidden_units': 64, 'dropout_rate': 0.5, 'fc_size': 8}\n",
      "Searching params: {'window_size': 3, 'learning_rate': 0.01, 'hidden_units': 64, 'dropout_rate': 0.5, 'fc_size': 16}\n",
      "Searching params: {'window_size': 3, 'learning_rate': 0.01, 'hidden_units': 64, 'dropout_rate': 0.5, 'fc_size': 32}\n",
      "Searching params: {'window_size': 3, 'learning_rate': 0.01, 'hidden_units': 64, 'dropout_rate': 0.5, 'fc_size': 64}\n",
      "Searching params: {'window_size': 3, 'learning_rate': 0.01, 'hidden_units': 128, 'dropout_rate': 0.0, 'fc_size': 8}\n",
      "Searching params: {'window_size': 3, 'learning_rate': 0.01, 'hidden_units': 128, 'dropout_rate': 0.0, 'fc_size': 16}\n",
      "Searching params: {'window_size': 3, 'learning_rate': 0.01, 'hidden_units': 128, 'dropout_rate': 0.0, 'fc_size': 32}\n",
      "Searching params: {'window_size': 3, 'learning_rate': 0.01, 'hidden_units': 128, 'dropout_rate': 0.0, 'fc_size': 64}\n",
      "Searching params: {'window_size': 3, 'learning_rate': 0.01, 'hidden_units': 128, 'dropout_rate': 0.3, 'fc_size': 8}\n",
      "Searching params: {'window_size': 3, 'learning_rate': 0.01, 'hidden_units': 128, 'dropout_rate': 0.3, 'fc_size': 16}\n",
      "Searching params: {'window_size': 3, 'learning_rate': 0.01, 'hidden_units': 128, 'dropout_rate': 0.3, 'fc_size': 32}\n",
      "Searching params: {'window_size': 3, 'learning_rate': 0.01, 'hidden_units': 128, 'dropout_rate': 0.3, 'fc_size': 64}\n",
      "Searching params: {'window_size': 3, 'learning_rate': 0.01, 'hidden_units': 128, 'dropout_rate': 0.5, 'fc_size': 8}\n",
      "Searching params: {'window_size': 3, 'learning_rate': 0.01, 'hidden_units': 128, 'dropout_rate': 0.5, 'fc_size': 16}\n",
      "Searching params: {'window_size': 3, 'learning_rate': 0.01, 'hidden_units': 128, 'dropout_rate': 0.5, 'fc_size': 32}\n",
      "Searching params: {'window_size': 3, 'learning_rate': 0.01, 'hidden_units': 128, 'dropout_rate': 0.5, 'fc_size': 64}\n",
      "Searching params: {'window_size': 3, 'learning_rate': 0.001, 'hidden_units': 16, 'dropout_rate': 0.0, 'fc_size': 8}\n",
      "Searching params: {'window_size': 3, 'learning_rate': 0.001, 'hidden_units': 16, 'dropout_rate': 0.0, 'fc_size': 16}\n",
      "Searching params: {'window_size': 3, 'learning_rate': 0.001, 'hidden_units': 16, 'dropout_rate': 0.0, 'fc_size': 32}\n",
      "Searching params: {'window_size': 3, 'learning_rate': 0.001, 'hidden_units': 16, 'dropout_rate': 0.0, 'fc_size': 64}\n",
      "Searching params: {'window_size': 3, 'learning_rate': 0.001, 'hidden_units': 16, 'dropout_rate': 0.3, 'fc_size': 8}\n",
      "Searching params: {'window_size': 3, 'learning_rate': 0.001, 'hidden_units': 16, 'dropout_rate': 0.3, 'fc_size': 16}\n",
      "Searching params: {'window_size': 3, 'learning_rate': 0.001, 'hidden_units': 16, 'dropout_rate': 0.3, 'fc_size': 32}\n",
      "Searching params: {'window_size': 3, 'learning_rate': 0.001, 'hidden_units': 16, 'dropout_rate': 0.3, 'fc_size': 64}\n",
      "Searching params: {'window_size': 3, 'learning_rate': 0.001, 'hidden_units': 16, 'dropout_rate': 0.5, 'fc_size': 8}\n",
      "Searching params: {'window_size': 3, 'learning_rate': 0.001, 'hidden_units': 16, 'dropout_rate': 0.5, 'fc_size': 16}\n",
      "Searching params: {'window_size': 3, 'learning_rate': 0.001, 'hidden_units': 16, 'dropout_rate': 0.5, 'fc_size': 32}\n",
      "Searching params: {'window_size': 3, 'learning_rate': 0.001, 'hidden_units': 16, 'dropout_rate': 0.5, 'fc_size': 64}\n",
      "Searching params: {'window_size': 3, 'learning_rate': 0.001, 'hidden_units': 32, 'dropout_rate': 0.0, 'fc_size': 8}\n",
      "Searching params: {'window_size': 3, 'learning_rate': 0.001, 'hidden_units': 32, 'dropout_rate': 0.0, 'fc_size': 16}\n",
      "Searching params: {'window_size': 3, 'learning_rate': 0.001, 'hidden_units': 32, 'dropout_rate': 0.0, 'fc_size': 32}\n",
      "Searching params: {'window_size': 3, 'learning_rate': 0.001, 'hidden_units': 32, 'dropout_rate': 0.0, 'fc_size': 64}\n",
      "Searching params: {'window_size': 3, 'learning_rate': 0.001, 'hidden_units': 32, 'dropout_rate': 0.3, 'fc_size': 8}\n",
      "Searching params: {'window_size': 3, 'learning_rate': 0.001, 'hidden_units': 32, 'dropout_rate': 0.3, 'fc_size': 16}\n",
      "Searching params: {'window_size': 3, 'learning_rate': 0.001, 'hidden_units': 32, 'dropout_rate': 0.3, 'fc_size': 32}\n",
      "Searching params: {'window_size': 3, 'learning_rate': 0.001, 'hidden_units': 32, 'dropout_rate': 0.3, 'fc_size': 64}\n",
      "Searching params: {'window_size': 3, 'learning_rate': 0.001, 'hidden_units': 32, 'dropout_rate': 0.5, 'fc_size': 8}\n",
      "Searching params: {'window_size': 3, 'learning_rate': 0.001, 'hidden_units': 32, 'dropout_rate': 0.5, 'fc_size': 16}\n",
      "Searching params: {'window_size': 3, 'learning_rate': 0.001, 'hidden_units': 32, 'dropout_rate': 0.5, 'fc_size': 32}\n",
      "Searching params: {'window_size': 3, 'learning_rate': 0.001, 'hidden_units': 32, 'dropout_rate': 0.5, 'fc_size': 64}\n",
      "Searching params: {'window_size': 3, 'learning_rate': 0.001, 'hidden_units': 64, 'dropout_rate': 0.0, 'fc_size': 8}\n",
      "Searching params: {'window_size': 3, 'learning_rate': 0.001, 'hidden_units': 64, 'dropout_rate': 0.0, 'fc_size': 16}\n",
      "Searching params: {'window_size': 3, 'learning_rate': 0.001, 'hidden_units': 64, 'dropout_rate': 0.0, 'fc_size': 32}\n",
      "Searching params: {'window_size': 3, 'learning_rate': 0.001, 'hidden_units': 64, 'dropout_rate': 0.0, 'fc_size': 64}\n",
      "Searching params: {'window_size': 3, 'learning_rate': 0.001, 'hidden_units': 64, 'dropout_rate': 0.3, 'fc_size': 8}\n",
      "Searching params: {'window_size': 3, 'learning_rate': 0.001, 'hidden_units': 64, 'dropout_rate': 0.3, 'fc_size': 16}\n",
      "Searching params: {'window_size': 3, 'learning_rate': 0.001, 'hidden_units': 64, 'dropout_rate': 0.3, 'fc_size': 32}\n",
      "Searching params: {'window_size': 3, 'learning_rate': 0.001, 'hidden_units': 64, 'dropout_rate': 0.3, 'fc_size': 64}\n",
      "Searching params: {'window_size': 3, 'learning_rate': 0.001, 'hidden_units': 64, 'dropout_rate': 0.5, 'fc_size': 8}\n",
      "Searching params: {'window_size': 3, 'learning_rate': 0.001, 'hidden_units': 64, 'dropout_rate': 0.5, 'fc_size': 16}\n",
      "Searching params: {'window_size': 3, 'learning_rate': 0.001, 'hidden_units': 64, 'dropout_rate': 0.5, 'fc_size': 32}\n",
      "Searching params: {'window_size': 3, 'learning_rate': 0.001, 'hidden_units': 64, 'dropout_rate': 0.5, 'fc_size': 64}\n",
      "Searching params: {'window_size': 3, 'learning_rate': 0.001, 'hidden_units': 128, 'dropout_rate': 0.0, 'fc_size': 8}\n",
      "Searching params: {'window_size': 3, 'learning_rate': 0.001, 'hidden_units': 128, 'dropout_rate': 0.0, 'fc_size': 16}\n",
      "Searching params: {'window_size': 3, 'learning_rate': 0.001, 'hidden_units': 128, 'dropout_rate': 0.0, 'fc_size': 32}\n",
      "Searching params: {'window_size': 3, 'learning_rate': 0.001, 'hidden_units': 128, 'dropout_rate': 0.0, 'fc_size': 64}\n",
      "Searching params: {'window_size': 3, 'learning_rate': 0.001, 'hidden_units': 128, 'dropout_rate': 0.3, 'fc_size': 8}\n",
      "Searching params: {'window_size': 3, 'learning_rate': 0.001, 'hidden_units': 128, 'dropout_rate': 0.3, 'fc_size': 16}\n",
      "Searching params: {'window_size': 3, 'learning_rate': 0.001, 'hidden_units': 128, 'dropout_rate': 0.3, 'fc_size': 32}\n",
      "Searching params: {'window_size': 3, 'learning_rate': 0.001, 'hidden_units': 128, 'dropout_rate': 0.3, 'fc_size': 64}\n",
      "Searching params: {'window_size': 3, 'learning_rate': 0.001, 'hidden_units': 128, 'dropout_rate': 0.5, 'fc_size': 8}\n",
      "Searching params: {'window_size': 3, 'learning_rate': 0.001, 'hidden_units': 128, 'dropout_rate': 0.5, 'fc_size': 16}\n",
      "Searching params: {'window_size': 3, 'learning_rate': 0.001, 'hidden_units': 128, 'dropout_rate': 0.5, 'fc_size': 32}\n",
      "Searching params: {'window_size': 3, 'learning_rate': 0.001, 'hidden_units': 128, 'dropout_rate': 0.5, 'fc_size': 64}\n",
      "Best params (by val F1): {'window_size': 3, 'learning_rate': 0.01, 'hidden_units': 16, 'dropout_rate': 0.0, 'fc_size': 8} Best thr: 0.03497203208582837\n",
      "        split  precision    recall        f1  threshold\n",
      "0       train   0.041030  0.980769  0.078764   0.034972\n",
      "1         val   1.000000  1.000000  1.000000   0.034972\n",
      "2        test   1.000000  1.000000  1.000000   0.034972\n",
      "3  ALL(micro)   0.043339  0.981818  0.083013   0.034972\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "def make_sequences_1d(series_1d, window_size):\n",
    "    X, y = create_sequences(series_1d.reshape(-1, 1), window_size)\n",
    "    # X shape: (N-window, window_size, 1); y: (N-window,)\n",
    "    return X, y\n",
    "\n",
    "def train_on_train_return_residuals(df_train, df_val, df_test, params, epochs=20):\n",
    "\n",
    "    scaler = MinMaxScaler()\n",
    "    train_y = df_train['Brouwer mean motion'].values.reshape(-1, 1)\n",
    "    scaler.fit(train_y)\n",
    "\n",
    "    y_tr = scaler.transform(train_y)\n",
    "    y_va = scaler.transform(df_val['Brouwer mean motion'].values.reshape(-1,1))\n",
    "    y_te = scaler.transform(df_test['Brouwer mean motion'].values.reshape(-1,1))\n",
    "\n",
    "    X_tr, y_tr_next = make_sequences_1d(y_tr, params['window_size'])\n",
    "    X_va, y_va_next = make_sequences_1d(y_va, params['window_size'])\n",
    "    X_te, y_te_next = make_sequences_1d(y_te, params['window_size'])\n",
    "\n",
    "    set_seed(42)\n",
    "    model = create_lstm_model(\n",
    "        window_size=params['window_size'],\n",
    "        n_features=1,\n",
    "        learning_rate=params['learning_rate'],\n",
    "        hidden_units=params['hidden_units'],\n",
    "        dropout_rate=params['dropout_rate'],\n",
    "        fc_size=params['fc_size']\n",
    "    )\n",
    "    model.fit(X_tr, y_tr_next, epochs=epochs, batch_size=32, shuffle=False, verbose=0)\n",
    "\n",
    "    res_tr = np.abs(y_tr_next - model.predict(X_tr, verbose=0).flatten())\n",
    "    res_va = np.abs(y_va_next - model.predict(X_va, verbose=0).flatten())\n",
    "    res_te = np.abs(y_te_next - model.predict(X_te, verbose=0).flatten())\n",
    "\n",
    "    idx_tr = df_train.index[params['window_size']:]\n",
    "    idx_va = df_val.index[params['window_size']:]\n",
    "    idx_te = df_test.index[params['window_size']:]\n",
    "\n",
    "    ser_tr = pd.Series(res_tr, index=idx_tr, name='residual')\n",
    "    ser_va = pd.Series(res_va, index=idx_va, name='residual')\n",
    "    ser_te = pd.Series(res_te, index=idx_te, name='residual')\n",
    "\n",
    "    return model, scaler, ser_tr, ser_va, ser_te\n",
    "\n",
    "param_grid = {\n",
    "    'window_size': [FIXED_WINDOW],      \n",
    "    'learning_rate': [0.01, 0.001],\n",
    "    'hidden_units': [16, 32, 64, 128],\n",
    "    'dropout_rate': [0.0, 0.3, 0.5],\n",
    "    'fc_size': [8, 16, 32, 64],\n",
    "}\n",
    "\n",
    "def evaluate_on_split(residual_series, man_dates_split, match_days=3, thresholds=None):\n",
    "    if thresholds is None:\n",
    "        thresholds = np.linspace(residual_series.min(), residual_series.max(), 500)\n",
    "    precisions, recalls = [], []\n",
    "    for thr in thresholds:\n",
    "        p, r = compute_simple_matching_precision_recall_for_one_threshold(\n",
    "            matching_max_days=match_days,\n",
    "            threshold=thr,\n",
    "            series_ground_truth_manoeuvre_timestamps=man_dates_split,\n",
    "            series_predictions=residual_series\n",
    "        )\n",
    "        precisions.append(p); recalls.append(r)\n",
    "    precisions = np.array(precisions); recalls = np.array(recalls)\n",
    "    f1 = 2*precisions*recalls/(precisions+recalls+1e-12)\n",
    "    return thresholds, precisions, recalls, f1\n",
    "\n",
    "search_records = []\n",
    "for lr in param_grid['learning_rate']:\n",
    "    for hu in param_grid['hidden_units']:\n",
    "        for dr in param_grid['dropout_rate']:\n",
    "            for fc in param_grid['fc_size']:\n",
    "                params = dict(window_size=FIXED_WINDOW, learning_rate=lr,\n",
    "                              hidden_units=hu, dropout_rate=dr, fc_size=fc)\n",
    "                print(\"Searching params:\", params)\n",
    "                model, scaler, ser_tr, ser_va, ser_te = train_on_train_return_residuals(\n",
    "                    df_train, df_val, df_test, params, epochs=20\n",
    "                )\n",
    "                thr, P, R, F1 = evaluate_on_split(ser_va, man_dates_val, match_days=3)\n",
    "                best_idx = np.argmax(F1)\n",
    "                search_records.append({\n",
    "                    'params': params,\n",
    "                    'best_thr_on_val': float(thr[best_idx]),\n",
    "                    'best_f1_on_val': float(F1[best_idx]),\n",
    "                    'P_on_val': float(P[best_idx]),\n",
    "                    'R_on_val': float(R[best_idx]),\n",
    "\n",
    "                    'ser_tr': ser_tr, 'ser_va': ser_va, 'ser_te': ser_te,\n",
    "                })\n",
    "\n",
    "\n",
    "search_df = pd.DataFrame([{k:v for k,v in rec.items() if k not in ['ser_tr','ser_va','ser_te']} for rec in search_records])\n",
    "best_rec = max(search_records, key=lambda r: r['best_f1_on_val'])\n",
    "best_params = best_rec['params']\n",
    "best_thr = best_rec['best_thr_on_val']\n",
    "print(\"Best params (by val F1):\", best_params, \"Best thr:\", best_thr)\n",
    "\n",
    "\n",
    "df_trval = pd.concat([df_train, df_val])\n",
    "\n",
    "def train_on_trval_and_get_residuals(df_trval, df_test, params, epochs=20):\n",
    "    scaler = MinMaxScaler()\n",
    "    y_trval = df_trval['Brouwer mean motion'].values.reshape(-1,1)\n",
    "    scaler.fit(y_trval)\n",
    "\n",
    "    y_trval_s = scaler.transform(y_trval)\n",
    "    y_test_s  = scaler.transform(df_test['Brouwer mean motion'].values.reshape(-1,1))\n",
    "\n",
    "    X_trv, y_trv_next = make_sequences_1d(y_trval_s, params['window_size'])\n",
    "    X_tst, y_tst_next = make_sequences_1d(y_test_s, params['window_size'])\n",
    "\n",
    "    set_seed(42)\n",
    "    model = create_lstm_model(\n",
    "        window_size=params['window_size'],\n",
    "        n_features=1,\n",
    "        learning_rate=params['learning_rate'],\n",
    "        hidden_units=params['hidden_units'],\n",
    "        dropout_rate=params['dropout_rate'],\n",
    "        fc_size=params['fc_size']\n",
    "    )\n",
    "    model.fit(X_trv, y_trv_next, epochs=epochs, batch_size=32, shuffle=False, verbose=0)\n",
    "\n",
    "    res_trv = np.abs(y_trv_next - model.predict(X_trv, verbose=0).flatten())\n",
    "    res_tst = np.abs(y_tst_next - model.predict(X_tst, verbose=0).flatten())\n",
    "\n",
    "    idx_trv = df_trval.index[params['window_size']:]\n",
    "    idx_tst = df_test.index[params['window_size']:]\n",
    "\n",
    "    ser_trv = pd.Series(res_trv, index=idx_trv, name='residual')\n",
    "    ser_tst = pd.Series(res_tst, index=idx_tst, name='residual')\n",
    "    return model, scaler, ser_trv, ser_tst\n",
    "\n",
    "final_model, final_scaler, ser_trval, ser_test = train_on_trval_and_get_residuals(\n",
    "    df_trval, df_test, best_params, epochs=20\n",
    ")\n",
    "\n",
    "def precision_recall_at_threshold(residual_series, man_dates_split, thr, match_days=3):\n",
    "    p, r = compute_simple_matching_precision_recall_for_one_threshold(\n",
    "        matching_max_days=match_days,\n",
    "        threshold=thr,\n",
    "        series_ground_truth_manoeuvre_timestamps=man_dates_split,\n",
    "        series_predictions=residual_series\n",
    "    )\n",
    "    f1 = 2*p*r/(p+r+1e-12)\n",
    "    return p, r, f1\n",
    "\n",
    "ser_train_best = best_rec['ser_tr']\n",
    "ser_val_best   = best_rec['ser_va']\n",
    "ser_test_final = ser_test  \n",
    "\n",
    "p_tr, r_tr, f1_tr = precision_recall_at_threshold(ser_train_best, man_dates_train, best_thr)\n",
    "p_va, r_va, f1_va = precision_recall_at_threshold(ser_val_best,   man_dates_val,   best_thr)\n",
    "p_te, r_te, f1_te = precision_recall_at_threshold(ser_test_final, man_dates_test,  best_thr)\n",
    "\n",
    "ser_all = pd.concat([ser_train_best, ser_val_best, ser_test_final]).sort_index()\n",
    "man_all = pd.concat([man_dates_train, man_dates_val, man_dates_test]).sort_values()\n",
    "\n",
    "p_all, r_all, f1_all = precision_recall_at_threshold(ser_all, man_all, best_thr)\n",
    "\n",
    "metrics_table = pd.DataFrame([\n",
    "    {'split':'train', 'precision':p_tr, 'recall':r_tr, 'f1':f1_tr, 'threshold':best_thr},\n",
    "    {'split':'val',   'precision':p_va, 'recall':r_va, 'f1':f1_va, 'threshold':best_thr},\n",
    "    {'split':'test',  'precision':p_te, 'recall':r_te, 'f1':f1_te, 'threshold':best_thr},\n",
    "    {'split':'ALL(micro)', 'precision':p_all, 'recall':r_all, 'f1':f1_all, 'threshold':best_thr},\n",
    "])\n",
    "print(metrics_table)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
